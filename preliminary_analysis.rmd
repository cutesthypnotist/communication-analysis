
Package installation
```{r}
install.packages("dplyr")
install.packages("tidyr")
install.packages("readr")
install.packages("pwr")
install.packages("fs")
install.packages("purrr")
install.packages("data.table")
install.packages("janitor")
install.packages("magrittr")
install.packages("tidyverse")
install.packages("stringr")
install.packages("ggpubr")
install.packages("ggplot2")
install.packages("rstatix")
```

Initialize commonly used libraries, variables, and functions.
```{r}

library(tidyr)
library(fs)
library(dplyr)
library(readr)
library(purrr)
library(data.table)
library(pwr)
library(janitor)
library(magrittr) 
library(tidyverse)
library(stringr)
library(ggpubr)
library(ggplot2)
library(rstatix)
library(qqplotr)
library(here)
library(tidyverse)
library(qqplotr)
library(rstatix)
library(broom)
library(knitr)
library(ggpubr)
library(gtools)
library(GGally)
library(correlation)
library(png)
library(patchwork)

# TODO: When we actually get around to analyzing the data, we need to create separate directories for 'good data',
# 'bad data', and 'output files' to keep things organized.

na_strings <- c("NA", "N/A", "na", "n/a", "NULL", "null", "None", "none", "NaN", "nan", "Inf", "-Inf", "inf", "-inf", "", " ")
names_with_indices <- function(data) {
  names_data <- names(data)
  indices <- seq_along(names_data)
  names_indexed <- paste(indices, names_data, sep = ": ")
  return(names_indexed)
}
# Function to fix the header and write a new CSV file
fix_csv_header_id <- function(file_path) {
  # Read the first line to check headers
  con <- file(file_path, open = "r")
  first_line <- readLines(con, n = 1)
  close(con)
  
  # Append ',id' to the first line
  corrected_first_line <- paste(first_line, "id", sep = ",")
  
  # Read the remaining lines of the original file
  remaining_lines <- read_lines(file_path, skip = 1)
  
  # Combine the corrected first line with the remaining lines
  corrected_content <- c(corrected_first_line, remaining_lines)
  
  # Define the new file path
  new_file_path <- paste0(sub(".csv", "", file_path), "_fixed.csv")
  
  # Write the corrected content to the new file
  writeLines(corrected_content, new_file_path)
  
  return(new_file_path)
}

# Function to fix the header and write a new CSV file with additional columns
fix_csv_header_cols <- function(file_path, additional_columns, suffix = "_fixed.csv") {
  # Read the first line to check headers
  con <- file(file_path, open = "r")
  first_line <- readLines(con, n = 1)
  close(con)
  
  # Append additional columns to the first line
  corrected_first_line <- paste(first_line, additional_columns, sep = ",")
  
  # Read the remaining lines of the original file
  remaining_lines <- read_lines(file_path, skip = 1)
  
  # Combine the corrected first line with the remaining lines
  corrected_content <- c(corrected_first_line, remaining_lines)
  
  # Define the new file path
  new_file_path <- paste0(sub(".csv", "", file_path), suffix)
  
  # Write the corrected content to the new file
  writeLines(corrected_content, new_file_path)
  
  return(new_file_path)
}



path_to_files <- "C:\\DataTest\\"
#path_to_files <- "C:\\Users\\Kit\\OneDrive\\Communication Experiment Data\\expLogs\\"


```



Test to fix missing column headers using function with parameters.

```{r}
path_to_files <- "C:\\DataTest\\"
files_fixed <- fs::dir_ls(path = path_to_files, recurse = TRUE, regexp = ".*[A-Z]{3}-\\d{4}-\\d{1,2} \\d{1,2}-\\d{1,2} Rating\\.csv$") %>%
  map(.f = function(file) {
    #cols_to_add <- "id"
    cols_to_add <- "id,rating,bwap,round_id,subject_id,gaze_condition,task_condition"
    suffix <- "_test.csv"
    #suffix <- "_fixed.csv"
    new_file <- fix_csv_header_cols(file, cols_to_add, suffix)
  })
files_fixed
path_to_files <- "C:\\Users\\Kit\\OneDrive\\Communication Experiment Data\\expLogs\\"
```


Fix the missing column headers
```{r}
files_fixed <- fs::dir_ls(path = path_to_files, recurse = TRUE, regexp = ".*[A-Z]{3}-\\d{4}-\\d{1,2} \\d{1,2}-\\d{1,2} Rating\\.csv$") %>%
  map(.f = function(file) {
    cols_to_add <- "id"
    #cols_to_add <- "id,rating,bwap,round_id,subject_id,gaze_condition,task_condition"
    #suffix <- "_test.csv"
    suffix <- "_fixed.csv"
    new_file <- fix_csv_header_cols(file, cols_to_add, suffix)
  })
files_fixed
```



Find the ones that are still in the older format.
```{r}
subject_ratings <- fs::dir_ls(path = path_to_files, recurse = TRUE, regexp = "[A-Z]{3}-\\d{4}-\\d{2} \\d{2}-\\d{2} Rating_fixed\\.csv$") %>%
  map_dfr(.f = function(subjects_file) {
    print(subjects_file)
    subject_row <- read_csv(subjects_file, na = na_strings, show_col_types = FALSE) %>% clean_names()
    subject_row
  }) 

subject_ratings <- subject_ratings %>% filter(round_id != 9) %>% mutate(subject_id = substr(subject_id, 1, 7))

# Ensure subject_ratings is a data frame
subject_ratings <- as.data.frame(subject_ratings)


test <- subject_ratings %>% filter(question == "How effective was your guidance in improving the student's focus?")
test


# Add a new column 'renamed_question' and fill it based on conditions
test2 <- subject_ratings %>%
  mutate(renamed_question = question) %>%  # Initialize with existing questions
  mutate(renamed_question = ifelse(grepl("Question - How confident were you in correctly guessing", question), "Confident", renamed_question)) %>%
  mutate(renamed_question = ifelse(grepl("Question - How easy was it to guide", question), "Ease", renamed_question)) %>%
  mutate(renamed_question = ifelse(grepl("Question - How well were you able to predict", question), "Predict", renamed_question)) %>%
  mutate(renamed_question = ifelse(grepl("Question - How would you rate your understanding", question), "Focus", renamed_question)) %>%
  mutate(renamed_question = ifelse(grepl("Question - How would you rate your awareness", question), "Awareness", renamed_question)) %>%
  mutate(renamed_question = ifelse(grepl("Question - How complex were your instructions when guiding", question), "Complex", renamed_question))


test3 <- test2 %>% group_by(subject_id, question) %>% summarise(mean_rating = mean(rating, na.rm = TRUE), .groups = "drop")

test4 <- test3 %>% filter(question == "Question - How confident did you feel")
test4

```



```{r}

subject_ratings 


aggregated_ratings <- subject_ratings %>%
  mutate(renamed_question = question) %>%  # Initialize with existing questions
  mutate(renamed_question = ifelse(grepl("Question - How confident were you in correctly guessing", question), "Confident", renamed_question)) %>%
  mutate(renamed_question = ifelse(grepl("Question - How easy was it to guide", question), "Ease", renamed_question)) %>%
  mutate(renamed_question = ifelse(grepl("Question - How well were you able to predict", question), "Predict", renamed_question)) %>%
  mutate(renamed_question = ifelse(grepl("Question - How would you rate your understanding", question), "Focus", renamed_question)) %>%
  mutate(renamed_question = ifelse(grepl("Question - How would you rate your awareness", question), "Awareness", renamed_question)) %>%
  mutate(renamed_question = ifelse(grepl("Question - How complex were your instructions when guiding", question), "Complex", renamed_question)) %>%
  group_by(subject_id, renamed_question, gaze_condition) %>%
  summarise(
    mean_rating = mean(rating, na.rm = TRUE),
    median_rating = median(rating, na.rm = TRUE), 
    .groups = "drop")
  
  aggregated_ratings
  # Split the data frame by question
  questions_list <- split(aggregated_ratings, aggregated_ratings$renamed_question)

  # Function to create and save a boxplot and scatter plot for each question
  plot_question <- function(data, question_name) {
    p <- ggplot(data, aes(x = gaze_condition, y = mean_rating, fill = gaze_condition)) +
      geom_boxplot(alpha = 0.5) +  # Set transparency to see scatter points clearly
      geom_point(position = position_jitter(width = 0.1), color = "black", size = 3, alpha = 0.6) +  # Add jitter to avoid overplotting
      labs(title = question_name, x = "Gaze Condition", y = "Mean Rating") +
      theme_classic() +
      scale_y_continuous(limits = c(1, 5), oob = scales::oob_squish)  # Force all data into the specified range

    # Save the plot
    ggsave(paste0("Boxplot_Scatter_", question_name, ".png"), plot = p, width = 10, height = 8, dpi = 300)
  }

```


```{r}
# Reshape data from long to wide format for each question type and gaze condition
wide_ratings <- aggregated_ratings %>%
  pivot_wider(names_from = c(renamed_question, gaze_condition), 
              values_from = mean_rating,
              names_sep = "_")

# Function to perform Wilcoxon signed-rank test for each question type
perform_wilcox_test <- function(data, question_name) {
  data_on <- data[[paste0(question_name, "_On")]]
  data_off <- data[[paste0(question_name, "_Off")]]
  test_result <- wilcox.test(data_on, data_off, paired = TRUE)
  return(test_result)
}

# List of all question types
question_types <- unique(aggregated_ratings$renamed_question)


wide_ratings
# Pivot data for plotting
wide_ratings_for_plots <- aggregated_ratings %>%
  pivot_wider(names_from = renamed_question, values_from = mean_rating)
  
wide_ratings_for_plots <- wide_ratings_for_plots %>% mutate(gaze_condition = factor(gaze_condition, levels = c("Off", "On")))

#Print out that this is results
print("Results")

awareness_wilcox <- wide_ratings_for_plots |> wilcox_test( Awareness ~ gaze_condition, paired=T) 
awareness_wilcox.p <- awareness_wilcox |> add_x_position(x="gaze_condition")
awareness_wilcox

wide_ratings_for_plots %>% ggplot(aes(x=gaze_condition, y=Awareness)) + 
  geom_count() +
  stat_summary(fun="median", geom="point", colour="orange") +
  coord_cartesian(ylim=c(1,6)) +
  scale_y_continuous(breaks=seq(1,5,1)) +
  theme_classic() +
  labs(title="How aware were you of the student's attention?", x="", y="") +
  stat_pvalue_manual(awareness_wilcox, label='p', hide.ns = T,
                     y.position = c(5.5))

#Now do it for Confident
confident_wilcox <- wide_ratings_for_plots |> wilcox_test( Confident ~ gaze_condition, paired=T)
confident_wilcox.p <- confident_wilcox |> add_x_position(x="gaze_condiition")
confident_wilcox

wide_ratings_for_plots %>% ggplot(aes(x=gaze_condition, y=Confident)) + 
  geom_count() +
  stat_summary(fun="median", geom="point", colour="orange") +
  coord_cartesian(ylim=c(1,6)) +
  scale_y_continuous(breaks=seq(1,5,1)) +
  theme_classic() +
  labs(title="How confident did you feel when guiding or correcting the student?", x="", y="") +
  stat_pvalue_manual(confident_wilcox, label='p', hide.ns = T,
                     y.position = c(5.5))

#Now do it for Ease

ease_wilcox <- wide_ratings_for_plots |> wilcox_test( Ease ~ gaze_condition, paired=T)
ease_wilcox.p <- ease_wilcox |> add_x_position(x="gaze_condiition")
ease_wilcox

wide_ratings_for_plots %>% ggplot(aes(x=gaze_condition, y=Ease)) + 
  geom_count() +
  stat_summary(fun="median", geom="point", colour="orange") +
  coord_cartesian(ylim=c(1,6)) +
  scale_y_continuous(breaks=seq(1,5,1)) +
  theme_classic() +
  labs(title="How easy was it to guide and correct the student?", x="", y="") +
  stat_pvalue_manual(ease_wilcox, label='p', hide.ns = T,
                     y.position = c(5.5))

#Now do it for Focus

focus_wilcox <- wide_ratings_for_plots |> wilcox_test( Focus ~ gaze_condition, paired=T)
focus_wilcox.p <- focus_wilcox |> add_x_position(x="gaze_condiition")
focus_wilcox

wide_ratings_for_plots %>% ggplot(aes(x=gaze_condition, y=Focus)) + 
  geom_count() +
  stat_summary(fun="median", geom="point", colour="orange") +
  coord_cartesian(ylim=c(1,6)) +
  scale_y_continuous(breaks=seq(1,5,1)) +
  theme_classic() +
  labs(title="How well did you understand the student's focus?", x="", y="") +
  stat_pvalue_manual(focus_wilcox, label='p', hide.ns = T,
                     y.position = c(5.5))




test_result_awareness <- perform_wilcox_test(wide_ratings, "Complex")
test_result_awareness

test_result_awareness <- perform_wilcox_test(wide_ratings, "Confident")
test_result_awareness

test_result_awareness <- perform_wilcox_test(wide_ratings, "Ease")
test_result_awareness

test_result_awareness <- perform_wilcox_test(wide_ratings, "Focus")
test_result_awareness

test_result_awareness <- perform_wilcox_test(wide_ratings, "Predict")
test_result_awareness

awareness_wilcox <- wide_ratings_for_plots |> wilcox_test( Awareness ~ gaze_condition, paired=T) 
awareness_wilcox.p <- awareness_wilcox |> add_x_position(x="gaze_condiition")
awareness_wilcox

wide_ratings_for_plots %>% ggplot(aes(x=gaze_condition, y=Awareness)) + 
  geom_count() +
  stat_summary(fun="median", geom="point", colour="orange") +
  coord_cartesian(ylim=c(1,6)) +
  scale_y_continuous(breaks=seq(1,5,1)) +
  theme_classic() +
  labs(title="Awareness", x="", y="") +
  stat_pvalue_manual(awareness_wilcox, label='p', hide.ns = T,
                     y.position = c(5.5))

# Plot w

# Apply the Wilcoxon test to each question type
test_results <- lapply(question_types, function(q) {
  # Perform the test
  test_result <- perform_wilcox_test(wide_ratings, q)
  list(question = q, wilcox_test_result = test_result)
})

# Output the test results
test_results
question_types
wide_ratings
#write_csv(wide_ratings, paste0(path_to_files, "wide_ratings_test.csv"))
```



```{r}

# Step 1: Group by subject_id and round_id to get the minimum unity_log_time along with gaze_condition
round_times <- subject_ratings %>%
  group_by(subject_id, round_id) %>%
  summarise(min_unity_log_time = min(unity_log_time, na.rm = TRUE),
            gaze_condition = first(gaze_condition)) %>%
  ungroup()

# Step 2: Calculate the duration of each round
# We use the `lag` function to get the previous round's min_unity_log_time
round_durations <- round_times %>%
  arrange(subject_id, round_id) %>%
  group_by(subject_id) %>%
  mutate(previous_time = lag(min_unity_log_time),
         round_duration = if_else(is.na(previous_time), min_unity_log_time, min_unity_log_time - previous_time))

round_durations

mean_durations <- round_durations %>%
  group_by(subject_id, gaze_condition) %>%
  summarise(mean_duration = mean(round_duration, na.rm = TRUE))

mean_durations

# Step 4: Reshape data from long to wide format
wide_mean_durations <- mean_durations %>%
  pivot_wider(names_from = gaze_condition, 
              values_from = mean_duration,
              names_prefix = "mean_duration_")

wide_mean_durations


# Assuming wide_mean_durations is already loaded with your data
# Ensure it's in the correct format
wide_mean_durations <- wide_mean_durations %>%
  pivot_longer(cols = starts_with("mean_duration"), names_to = "gaze_condition", values_to = "mean_duration") %>%
  mutate(gaze_condition = sub("mean_duration_", "", gaze_condition))

# Make it a data frame
wide_mean_durations <- wide_mean_durations %>% as.data.frame()
wide_mean_durations
# Perform Wilcoxon signed-rank test using rstatix
duration_wilcox <- wide_mean_durations %>%
  wilcox_test(mean_duration ~ gaze_condition, paired = TRUE)
duration_wilcox.p <- duration_wilcox |> add_x_position(x="gaze_condition")
duration_wilcox


# Plotting the results
wide_mean_durations |> ggplot(aes(x = gaze_condition, y = mean_duration, fill = gaze_condition)) +
  #geom_boxplot() +
  #geom_jitter(width = 0.1, alpha = 0.5) +
  geom_count() +
  scale_y_continuous(limits = c(0, 500), breaks = seq(0, 500, 50)) +
  labs(title = "Comparison of Mean Durations by Gaze Condition", x = "Gaze Condition", y = "Mean Duration") +
  theme_minimal() +
  scale_fill_manual(values = c("Off" = "blue", "On" = "red")) +
  ggpubr::stat_pvalue_manual(duration_wilcox, label = "p", hide.ns = TRUE, y.position = 450)
```



```{r}

# Perform Wilcoxon signed-rank test
wilcox_test_result <- wilcox.test(
  wide_mean_durations$mean_duration[wide_mean_durations$gaze_condition == "Off"],
  wide_mean_durations$mean_duration[wide_mean_durations$gaze_condition == "On"],
  paired = TRUE
)

# Create a manual p-value annotation data frame
p_value_data <- data.frame(
  x = 1.5, 
  y = 450, 
  label = paste("p-value:", formatC(wilcox_test_result$p.value, format = "e", digits = 2))
)

# Plotting the results
ggplot(wide_mean_durations, aes(x = gaze_condition, y = mean_duration, fill = gaze_condition)) +
  geom_boxplot() +
  geom_jitter(width = 0.1, alpha = 0.5) +
  scale_y_continuous(limits = c(0, 350), breaks = seq(0, 350, 50)) +
  labs(title = "Comparison of Mean Round (3 Tasks) Durations by Gaze Condition", x = "Gaze Condition", y = "Mean Duration") +
  theme_minimal() +
  scale_fill_manual(values = c("Off" = "blue", "On" = "red")) +
  geom_text(data = p_value_data, aes(x = x, y = y, label = label), inherit.aes = FALSE)
```

```{r}
  # Apply the function to each item in the list
  lapply(names(questions_list), function(q) {
    plot_question(questions_list[[q]], q)
  })
```

Not sure but I think this chunk doesn't work.
```{r}

# Add a new column 'renamed_question' with the shortened question text
subject_ratings <- subject_ratings %>%
  mutate(renamed_question = case_when(
    grepl("How effective was your guidance in improving", question) ~ "Effectiveness",
    grepl("How easy was it to guide and correct ", question) ~ "Ease",
    grepl("How efficiently could you guide and correct the ", question) ~ "Efficiency",
    grepl("How would you rate your understanding of the student's focus", question) ~ "Focus",
    grepl("How would you rate your awareness about the student's", question) ~ "Awareness",
    grepl("How confident did you feel", question) ~ "Confidence",
    TRUE ~ question
  ))

# Now perform the aggregation using the new 'renamed_question' column
aggregated_ratings <- subject_ratings %>%
  filter(round_id != 9) %>%
  group_by(subject_id = substr(subject_id, 1, 7), renamed_question, gaze_condition) %>%
  summarise(mean_rating = mean(rating, na.rm = TRUE), .groups = "drop")


aggregated_ratings
# Add a new column 'renamed_question' with the shortened question text
subject_ratings[, renamed_question := fcase(
  grepl("How effective was your guidance in improving", question), "Effectiveness",
  grepl("How easy was it to guide and correct ", question), "Ease",
  grepl("How efficiently could you guide and correct the ", question), "Efficiency",
  grepl("How would you rate your understanding of the student's focus", question), "Focus",
  grepl("How would you rate your awareness about the student's", question), "Awareness",
  grepl("How confident did you feel", question), "Confidence",
  default = question
)]



# Now perform the aggregation using the new 'renamed_question' column
aggregated_ratings <- subject_ratings[round_id != 9, 
  .(mean_rating = mean(rating, na.rm = TRUE)), 
  by = .(subject_id = substr(subject_id, 1, 7), renamed_question, gaze_condition)
]


aggregated_ratings <- subject_ratings %>%
  dplyr::filter(round_id != 9) %>%
  group_by(subject_id, question, gaze_condition) %>%
  mutate(subject_id = substr(subject_id, 1, 7),
         question = str_replace_all(question, "Question - How effective was your guidance in improving", "Effectiveness"),
         question = str_replace_all(question, "Question - How easy was it to guide and correct ", "Ease"),
         question = str_replace_all(question, "Question - How efficiently could you guide and correct the ", "Efficiency"),
         question = str_replace_all(question, "Question - How would you rate your understanding of the student's focus", "Focus"),
         question = str_replace_all(question, "Question - How would you rate your awareness about the student's", "Awareness"),
         question = str_replace_all(question, "Question - How confident did you feel", "Confidence")) %>%
  summarise(mean_rating = mean(rating, na.rm = TRUE), .groups = "drop")
  

aggregated_ratings

# Split the data frame by question
questions_list <- split(aggregated_ratings, aggregated_ratings$question)

# Function to create and save a boxplot for each question
plot_question <- function(data, question_name) {
  p <- ggplot(data, aes(x = gaze_condition, y = mean_rating, fill = gaze_condition)) +
    geom_boxplot() +
    labs(title = question_name, x = "Gaze Condition", y = "Mean Rating") +
    theme_minimal()
  
  # Save the plot
  ggsave(paste0("Boxplot_", question_name, ".png"), plot = p, width = 10, height = 8, dpi = 300)
}

# Apply the function to each item in the list
lapply(names(questions_list), function(q) {
  plot_question(questions_list[[q]], q)
})

```




For each subject we want to figure out their mean rating for each gaze condition. Also we want to only take the first 7 characters of the subject ID.
```{r}

subject_ratings <- fs::dir_ls(path = path_to_files, recurse = TRUE, regexp = "[A-Z]{3}-\\d{4}-\\d{2} \\d{2}-\\d{2} Rating_fixed\\.csv$") %>%
  map_dfr( .f = function(subjects_file) {
    print(subjects_file)
    subject_row <- read_csv(subjects_file, na = na_strings, show_col_types = FALSE) %>% clean_names()
    subject_row
  }) 

subject_ratings

aggregated_ratings <- subject_ratings %>%
  dplyr::filter(round_id != 9) %>%
  group_by(subject_id, question, gaze_condition) %>%
  summarise(mean_rating = mean(rating, na.rm = TRUE), .groups = "drop") %>%
  mutate(subject_id = substr(subject_id, 1, 7))
aggregated_ratings

write_csv(aggregated_ratings, paste0(path_to_files, "aggregated_ratings.csv"))
```


```{r}
aggregated_ratings <- fs::dir_ls(path = path_to_files, recurse = TRUE, regexp = "[A-Z]{3}-\\d{4}-\\d{2} \\d{2}-\\d{2} Rating_fixed\\.csv$") %>%
  map_dfr(.f = function(subjects_file) {
    print(subjects_file)
    subject_row <- read_csv(subjects_file, na = na_strings, show_col_types = FALSE) %>% clean_names()
    subject_row
  }) %>%
  filter(round_id != 9) %>%
  group_by(subject_id, gaze_condition) %>%
  summarise(mean_rating = mean(rating, na.rm = TRUE), .groups = "drop") %>%
  mutate(subject_id = substr(subject_id, 1, 7)) %>%
  pivot_wider(names_from = gaze_condition, values_from = mean_rating) %>%
  mutate(difference = `Off` - `On`)

# Add a column to indicate positive or negative difference
aggregated_ratings <- aggregated_ratings %>%
  mutate(difference_sign = ifelse(difference > 0, "Positive", "Negative"))

aggregated_ratings
```



Step 1 of counterbalancing strategy in the user study where we generate count of each order experienced. This mitigates order effects (such as subjects improving by repetition or performing worse due to fatigue), reduces variability from order and carryover effects, and allows for easier advanced analysis (e.g. ANOVA), thus increasing the likelihood of detecting significant effects.
```{r}

merge_subjects <- fs::dir_ls(path = path_to_files, recurse = TRUE, regexp = "participantData\\.csv$") %>%
  map_dfr( .f = function(subjects_file) {
    print(subjects_file)
    subject_row <- read_csv(subjects_file, na = na_strings, show_col_types = FALSE) %>% clean_names() %>% select(-c(1))
    subject_row
  })


head(merge_subjects)
names_with_indices(merge_subjects)

# Split the gaze condition order into x-x-x-x
merge_subjects <- merge_subjects %>%
  mutate(First_Part = substr(gaze_condition_order, 1, 7),
         Second_Part = substr(gaze_condition_order, 9, 15)) %>%
  select(-gaze_condition_order) %>%
  pivot_longer(cols = c(First_Part, Second_Part), 
               names_to = "Part", 
               values_to = "gaze_condition_order") %>%
  select(-Part)
merge_subjects

# Now get the count of each gaze condition order
gaze_order_counts <- merge_subjects %>% 
  group_by(gaze_condition_order) %>%
  summarise(count = n(), .groups = "drop")

# Rename gaze_condition_order to just conditions
gaze_order_counts <- gaze_order_counts %>% rename(conditions = gaze_condition_order)
gaze_order_counts
write_csv(gaze_order_counts, paste0(path_to_files, "conditions.csv"))
```

Now we want to do some preliminary analysis on ratings given. First we need to merge all subject rating data into a single DataFrame.
```{r}
# Function to merge all CSV files into one DataFrame
merge_csv_files <- function(datapath) {
  # List all CSV files in the directory with the specified pattern
  csv_files <- fs::dir_ls(path = datapath, recurse = TRUE, regexp = "^[A-Z]{3}-\\d{4}-\\d{2} \\d{2}-\\d{2} Rating\\.csv$")

  # Read and concatenate all files into one DataFrame
  combined_data <- csv_files %>%
    map_dfr(read_csv, .id = "file_name")  # Optionally include file name as an identifier column

  return(combined_data)
}

all_data <- merge_csv_files(path_to_files)

# Optional: Save the combined DataFrame to a CSV file
write_csv(all_data, "ratings_preliminary_merged.csv")
```

Compute the average rating for each subject_id under each gaze_condition.

```{r}
# Transform the data to calculate the average rating for each subject_id within each condition combination
data_transformed <- data %>%
    group_by(subject_id, gaze_condition, task_condition) %>%
    summarise(mean_rating = mean(Rating, na.rm = TRUE)) %>%
    ungroup()

# View the transformed data
head(data_transformed)
```

Power analysis
```{r}
# Calculate the sample sizes required for small, medium, and large effect sizes
effect_sizes <- c(small = 0.2, medium = 0.5, large = 0.8)
names(effect_sizes) <- c("Small", "Medium", "Large")

# Use a loop to calculate required sample sizes for each effect size
sample_sizes <- setNames(numeric(length(effect_sizes)), names(effect_sizes))
for (es in names(effect_sizes)) {
    pwr_result <- pwr.anova.test(
        k = 4, # for a 2x2 factorial design, we have 4 groups
        f = effect_sizes[es], # f is the effect size for ANOVA
        sig.level = 0.05,
        power = 0.8
    )
    sample_sizes[es] <- ceiling(pwr_result$n) # n per group
}
# Output the required sample sizes for each effect size
sample_sizes
```

How many more subjects do we need?
```{r}

current_sample_size <- data_transformed %>%
    count(gaze_condition, task_condition)

additional_subjects_needed <- sapply(sample_sizes, function(size) {
    required_total <- size * 4 # total required for all groups
    current_total <- sum(current_sample_size$n)
    max(0, required_total - current_total)
})

# Output the number of additional subjects needed for each effect size
additional_subjects_needed
```
